{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTwDFnjHMk25"
      },
      "source": [
        "# CSE547 - Colab 0\n",
        "## Spark Tutorial\n",
        "\n",
        "In this tutorial we will learn how to use [Apache Spark](https://spark.apache.org) in local mode on a Colab enviroment.\n",
        "\n",
        "This is adapted from the Spark Tutorial used in the Applied Data Analysis class at EPFL taught by [Tiziano Piccardi](http://piccardi.me/), which was in turn adapted From Stanford's CS246."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXQzA01OS_yQ"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbYZoVVWOZA5"
      },
      "source": [
        "We'll begin by setting Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhzk3GE6S9RC"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt update\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctU1dYjfOif7"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the file we will be processing in our Spark job. **Make sure to follow the interactive instructions, and allow Google Drive to save the data files.** Alternatively, download the files directly (see links below) and then upload them into your Colab instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dfnX7IAOkvH"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF5nuSdyTJpc"
      },
      "outputs": [],
      "source": [
        "id='1yUNY2zq8NRn2LGsDurXqBwXv5XrqmIeH'\n",
        "downloaded = drive.CreateFile({'id': id}) \n",
        "downloaded.GetContentFile('title.basics.tsv.gz')\n",
        "\n",
        "id='1NY8-Hip68lS04FlaoZBTCSWf8wyKvK4h'\n",
        "downloaded = drive.CreateFile({'id': id}) \n",
        "downloaded.GetContentFile('title.principals.tsv.gz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA49WWqmO5rR"
      },
      "source": [
        "We should now see the files *title.basics.tsv.gz* and *title.principals.tsv.gz* under the \"Files\" tab on the left panel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgQaRx6rSaf9"
      },
      "outputs": [],
      "source": [
        "# Import the libraries we will need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUD5XpD_SagA"
      },
      "source": [
        "We first initialize the Spark context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ft3VivrSagB"
      },
      "outputs": [],
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n20ixkgSagD"
      },
      "source": [
        "We can easily check the current version and get the link of the web interface. In the Spark UI, we can monitor the progress of our job and debug performance bottlenecks (only when the Colab is running with a **local runtime**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl4RHbqFSagE"
      },
      "outputs": [],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlw1Mgx0T9-l"
      },
      "source": [
        "If, however, we choose to run this Colab on a Google hosted runtime, the cell below will create an *ngrok* tunnel which will allow us to check the Spark UI.\n",
        "\n",
        "(Note: this cell is sometimes flaky.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYYlUTWYQMjb"
      },
      "outputs": [],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url']);\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gewv-lKMSagI"
      },
      "source": [
        "# IMDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skjUv84VSagJ"
      },
      "source": [
        "----\n",
        "\n",
        "\n",
        "**The IMDB dataset describes TV, film, and other media titles listed on the IMDB site.**\n",
        "\n",
        "This dataset consists of multiple tables, but we use only two for this lab. The below descriptions are copied from the IMDB dataset [interfaces page](https://www.imdb.com/interfaces/).\n",
        "\n",
        "**Title Basic Information** [IMDB link](https://datasets.imdbws.com/title.basics.tsv.gz)\n",
        "- tconst (string) - alphanumeric unique identifier of the title\n",
        "- titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
        "- primaryTitle (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
        "- originalTitle (string) - original title, in the original language\n",
        "- isAdult (boolean) - 0: non-adult title; 1: adult title\n",
        "- startYear (YYYY) – represents the release year of a title. In the case of TV Series, it is the series start year\n",
        "- endYear (YYYY) – TV Series end year. ‘\\N’ for all other title types\n",
        "- runtimeMinutes – primary runtime of the title, in minutes\n",
        "- genres (string array) – includes up to three genres associated with the title\n",
        "\n",
        "**Principal Cast/Crew** [IMDB link](https://datasets.imdbws.com/title.principals.tsv.gz)\n",
        "- tconst (string) - alphanumeric unique identifier of the title\n",
        "- ordering (integer) – a number to uniquely identify rows for a given titleId\n",
        "- nconst (string) - alphanumeric unique identifier of the name/person\n",
        "- category (string) - the category of job that person was in\n",
        "- job (string) - the specific job title if applicable, else '\\N'\n",
        "- characters (string) - the name of the character played if applicable, else '\\N'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSWoULeWSagJ"
      },
      "source": [
        "First, we load the datasets into Spark DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLyVPuLXSagK"
      },
      "outputs": [],
      "source": [
        "Titles = spark.read.csv(\"title.basics.tsv.gz\", sep='\\t', header=True)\n",
        "Principals = spark.read.csv(\"title.principals.tsv.gz\", sep='\\t', header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP2JmCeoSagM"
      },
      "source": [
        "We can check the schema of each DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpUT8viNSagM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0541f3ff-3545-4426-95fd-abdae6c219ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- tconst: string (nullable = true)\n",
            " |-- titleType: string (nullable = true)\n",
            " |-- primaryTitle: string (nullable = true)\n",
            " |-- originalTitle: string (nullable = true)\n",
            " |-- isAdult: string (nullable = true)\n",
            " |-- startYear: string (nullable = true)\n",
            " |-- endYear: string (nullable = true)\n",
            " |-- runtimeMinutes: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Titles.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LJsbmlxSagO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7114a77-540d-4039-9e63-cbba89a47abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- tconst: string (nullable = true)\n",
            " |-- ordering: string (nullable = true)\n",
            " |-- nconst: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- characters: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Principals.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jP5IBezSagQ"
      },
      "source": [
        "`take()` returns a sample of rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrJpiG5ISagQ"
      },
      "outputs": [],
      "source": [
        "Titles.take(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu7n8KKjSagS"
      },
      "source": [
        "`show()` returns a *formatted* sample of rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwYZrwanSagT"
      },
      "outputs": [],
      "source": [
        "Principals.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMAab2rJSagU"
      },
      "outputs": [],
      "source": [
        "print(f\"In total there are {Titles.count():,d} IMDB titles.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xy_2ZitTFtV"
      },
      "source": [
        "We'll do a little bit of preprocessing here to remove any titles with a null title type or start year field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atfpEfTBdZEz"
      },
      "outputs": [],
      "source": [
        "Titles = Titles.replace({'\\\\N': None}).dropna(subset=['titleType', 'startYear'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP-IIAKHTVxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a95445f-5b35-4fef-ace4-402c82a5c69c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After preprocessing, there are 8,127,526 IMDB titles.\n"
          ]
        }
      ],
      "source": [
        "print(f\"After preprocessing, there are {Titles.count():,d} IMDB titles.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkKWEEcLSagW"
      },
      "source": [
        "## Question 1: How many titles of each type are in the IMDB dataset?\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Keywords: `Dataframe API`, `SQL`, `group by`, `sort`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwPL1-P5SagW"
      },
      "source": [
        "IMDB lists many different kinds of media -- movies, video games, TV episodes, etc. Let's group the IMDB titles by `titleType` and count how many records exist belonging to each title type:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWcMVcgwSagX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "title_type_counts = Titles.groupBy(\"titleType\")\\\n",
        "                                    .agg(count(\"*\").alias(\"numTitles\"))\\\n",
        "                                    .sort(desc(\"numTitles\"))\n",
        "title_type_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5trEAkzSagY"
      },
      "source": [
        "In this case we use the Spark DataFrame API, but we could rewite this query using pure SQL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3slo-sXOSagZ"
      },
      "outputs": [],
      "source": [
        "Titles.registerTempTable(\"Titles\")\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT titleType, count(*) as numTitles\n",
        "FROM Titles\n",
        "GROUP BY titleType\n",
        "ORDER BY numTitles DESC\n",
        "\"\"\"\n",
        "\n",
        "title_type_counts = spark.sql(query)\n",
        "title_type_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wQNXQnOSaga"
      },
      "source": [
        "This Dataframe is small enough to be moved to Pandas, so we create a Pandas DataFrame object with all of the affordances of the Pandas API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nVJdPLDSagb"
      },
      "outputs": [],
      "source": [
        "title_type_count_pd = title_type_counts.toPandas()\n",
        "title_type_count_pd.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQedtuQZSagc"
      },
      "source": [
        "We visualize this title type information by plotting a barchart with the number of titles by type:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgbceprDSagd"
      },
      "outputs": [],
      "source": [
        "pl = title_type_count_pd.plot(kind=\"bar\", \n",
        "                            x=\"titleType\", y=\"numTitles\", \n",
        "                            figsize=(10, 7), log=True, alpha=0.5, color=\"olive\")\n",
        "pl.set_xlabel(\"Type of Title\")\n",
        "pl.set_ylabel(\"Number of Titles (Log scale)\")\n",
        "pl.set_title(\"Number of Titles by Type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jCZfwK2Sage"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLan66cXSagf"
      },
      "source": [
        "## Questions 2: Show the number of titles started in every year, by type of title (TV episode, short, movie, etc).\n",
        "\n",
        "Keywords: `group by`, `parse date`, `plot`\n",
        "\n",
        "We begin by selecting the relevant columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXNKt5PHSagf"
      },
      "outputs": [],
      "source": [
        "year_titles = Titles.selectExpr([\"titleType\", \"startYear\"])\n",
        "year_titles.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da9IeKntSagh"
      },
      "source": [
        "Now we use the `.groupBy()` function from the Spark DataFrame API to get the number of titles with each  `titleType` and `startYear`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLza0bF9Sagh"
      },
      "outputs": [],
      "source": [
        "titles_by_year_and_type = year_titles\\\n",
        "                    .groupBy([\"titleType\", \"startYear\"])\\\n",
        "                    .agg(count(\"*\").alias(\"numTitles\"))\\\n",
        "                    .sort(asc(\"startYear\")).toPandas()\n",
        "titles_by_year_and_type.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAhOE55wSagj"
      },
      "source": [
        "We plot this data using a different series for each type of IMDB title:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLq6ulAySagl"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n",
        "\n",
        "# iterate the different groups to create a different series\n",
        "for titleType, titles in titles_by_year_and_type.groupby(\"titleType\"): \n",
        "    plt.plot(\n",
        "        pd.to_numeric(titles[\"startYear\"]), titles[\"numTitles\"], label=titleType\n",
        "    )\n",
        "\n",
        "plt.yscale('log')\n",
        "plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEMzTwxGSagp"
      },
      "source": [
        "We now observe that titles of the 'short' and 'movie' types increase in count in the 1890s and 1900s. Other title types, which all depend on distribution via household TVs, increase in count much later, around the 1940s-1950s. This intuitively coincides with TVs becoming more prevalent in households; in the US, household TV ownership rose from 9% to almost 90% during the 1950s.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl6m0B6iSagp"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEwBspLySagp"
      },
      "source": [
        "## Question 3: What was the most popular genre of movie in 2000?\n",
        "\n",
        "Keywords: `RDD map reduce` `cache` `save results`\n",
        "\n",
        "\n",
        "We are interested in discovering what genre of movie was the most common  during the year of 2000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qurjwd0zSagr"
      },
      "source": [
        "We begin by filtering for movies that start in 2000:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq6jqsgBSagq"
      },
      "outputs": [],
      "source": [
        "year2000_movies = Titles.where(\"titleType='movie' AND startYear='2000'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PcIgTzuITS2"
      },
      "source": [
        "We now split the genres column, which is currently formatted as a string, into an array of strings, then explode -- which means that we expand each row in the existing DataFrame by creating a copy of it for each distinct value in that array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzdwtiVzJAKm"
      },
      "outputs": [],
      "source": [
        "year2000_movies = year2000_movies.select([\"*\", explode(split(Titles.genres, '[,]', 3)).alias(\"genre\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLec-CkmSagu"
      },
      "outputs": [],
      "source": [
        "year2000_movies.show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoiVSE7NSags"
      },
      "outputs": [],
      "source": [
        "year2000_movies.groupBy(\"genre\").agg(count(\"*\").alias(\"numTitles\")).sort(desc(\"numTitles\")).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0Q2bS4KSagt"
      },
      "source": [
        "'Drama' was the most common genre in IMDB movies of 2000, with 1825 movies being listed as dramas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77XdZuNDSagv"
      },
      "source": [
        "We can cache the content in memory, which saves time for repeat operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q45a-OYwSagw"
      },
      "outputs": [],
      "source": [
        "year2000_movies.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feWOqgKISagx"
      },
      "source": [
        "Now we count the number of rows and move the content to the cache:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIpLEQrlSagx"
      },
      "outputs": [],
      "source": [
        "%time year2000_movies.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCTEq5LZSagz"
      },
      "source": [
        "The second time we call `.count()`, the content has been cached and the operation is much faster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oZtHYspSagz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45bd3673-a0bf-44ba-d0ed-d7526ebbf8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.38 ms, sys: 0 ns, total: 2.38 ms\n",
            "Wall time: 85.4 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7049"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "%time year2000_movies.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Hzke2kSag1"
      },
      "source": [
        "We can also save the results in a file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_2p0Ha9Sag1"
      },
      "outputs": [],
      "source": [
        "year2000_movies.write.mode('overwrite').json(\"year2000_movies.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJwG61TNSag3"
      },
      "source": [
        "We can then read from that file into a Spark DataFrame again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTe1l78_Sag4"
      },
      "outputs": [],
      "source": [
        "year2000_movies = spark.read.json(\"year2000_movies.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEW08u3_Sag6"
      },
      "source": [
        "As a reminder, we were previously using the Spark DataFrame API, as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYO-CuHISag8"
      },
      "outputs": [],
      "source": [
        "Counts = year2000_movies\\\n",
        "                .groupBy(\"genre\").agg(count(\"*\").alias(\"numTitles\")).sort(desc(\"numTitles\"))\n",
        "Counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PHZStWQSag9"
      },
      "source": [
        "But we can also do the same operations using the explicit Map-Reduce format with RDDs.\n",
        "\n",
        "First we output, from each row, a tuple of data with format (genre, 1):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgEeKdtYSag9"
      },
      "outputs": [],
      "source": [
        "all_genres = year2000_movies.rdd.map(lambda row: (row.genre, 1))\n",
        "all_genres.take(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akm81xVxSag_"
      },
      "source": [
        "Then, we sum the counters in the reduce step, and we sort the resulting data by count:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hVvIF_WSag_"
      },
      "outputs": [],
      "source": [
        "genres_counts_rdd = all_genres.reduceByKey(lambda a, b: a+b)\\\n",
        "                                      .sortBy(lambda r: -r[1])\n",
        "genres_counts_rdd.take(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od5h9c6qSahB"
      },
      "source": [
        "Now we can convert the RDD to a DataFrame by mapping the pairs to objects of type `Row`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNDn84R_SahB"
      },
      "outputs": [],
      "source": [
        "genres_counts_with_schema = genres_counts_rdd\\\n",
        "                      .map(lambda r: Row(genre=r[0], numTitles=r[1]))\n",
        "genres_counts = spark.createDataFrame(genres_counts_with_schema)\n",
        "genres_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE8asfBPSahD"
      },
      "source": [
        "\n",
        "As we see, the results with Map-Reduce match the results we had previously when conducting this query with the DataFrame API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKKM6VS8SahD"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaiVcdF8SahD"
      },
      "source": [
        "## Questions 4: What is the most common category of job for someone working on an IMDB title in 1980?\n",
        "\n",
        "Keywords: `join` `group by`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnV48FZlSahG"
      },
      "source": [
        "We begin by inspecting the content of `Principals`, which contains the principal cast and crew on each IMDB title:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yovhBV5sSahI",
        "outputId": "b2fe60e0-777b-43a7-eb53-f5fdce036cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+---------+---------------+--------------------+----------+\n",
            "|   tconst|ordering|   nconst|       category|                 job|characters|\n",
            "+---------+--------+---------+---------------+--------------------+----------+\n",
            "|tt0000001|       1|nm1588970|           self|                  \\N|  [\"Self\"]|\n",
            "|tt0000001|       2|nm0005690|       director|                  \\N|        \\N|\n",
            "|tt0000001|       3|nm0374658|cinematographer|director of photo...|        \\N|\n",
            "|tt0000002|       1|nm0721526|       director|                  \\N|        \\N|\n",
            "|tt0000002|       2|nm1335271|       composer|                  \\N|        \\N|\n",
            "+---------+--------+---------+---------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Principals.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO0ExxRoSahJ"
      },
      "source": [
        "We are interested in the field `category`, which lists the category of job occupied by the cast or crew member."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4DnpCTmSahJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944a4c38-21b6-4fd8-c58c-ba9f64193daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|       category|\n",
            "+---------------+\n",
            "|           self|\n",
            "|       director|\n",
            "|cinematographer|\n",
            "|       director|\n",
            "|       composer|\n",
            "+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Principals.select(\"category\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oviDiha9QCwl"
      },
      "source": [
        "From the `Titles` dataframe, we first select all titles with `startYear` of 1980:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76zJUAUPQDBX"
      },
      "outputs": [],
      "source": [
        "year1980_titles = Titles.where(\"startYear='1980'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z97Y9DuUSahK"
      },
      "source": [
        "We now join on the column `tconst` of both dataframes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9txA3mx1SahL"
      },
      "source": [
        "With the Spark Dataframe API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHH_GoChnF0S"
      },
      "outputs": [],
      "source": [
        "titles_joined = Principals.join(\n",
        "                  year1980_titles, Principals.tconst == year1980_titles.tconst)\n",
        "titles_joined.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhQbN8AOSahN"
      },
      "source": [
        "We can select only the field we are interested in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5KgFBXASahO"
      },
      "outputs": [],
      "source": [
        "title_job_categories = titles_joined.select(\"category\")\n",
        "title_job_categories.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giUuCERTSahT"
      },
      "source": [
        "And finally, we can group by `category` and then aggregate and count:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0QytpygSahU"
      },
      "outputs": [],
      "source": [
        "title_job_categories.groupBy(\"category\").agg(count(\"*\").alias(\"numPrincipals\"))\\\n",
        "                  .sort(desc(\"numPrincipals\"))\\\n",
        "                  .show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y1043GMSahV"
      },
      "source": [
        "Alternatively, we can rewrite this query in pure SQL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "980KMZCOSahV"
      },
      "outputs": [],
      "source": [
        "year1980_titles.registerTempTable(\"Year1980Titles\")\n",
        "Principals.registerTempTable(\"Principals\")\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT category, count(*) numPrincipals\n",
        "FROM Year1980Titles ti\n",
        "JOIN Principals pr\n",
        "ON ti.tconst = pr.tconst\n",
        "GROUP BY category\n",
        "ORDER BY numPrincipals DESC\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffrW-oV2SahW"
      },
      "source": [
        "The job category of `actor` was most common in IMDB titles from 1980. The second most common job category was `actress`. Further data preprocessing might merge these two categories into a single non-gendered category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc20F-RNMXZL"
      },
      "outputs": [],
      "source": [
        "get_ipython().system_raw('./ngrok http 4050 &')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}